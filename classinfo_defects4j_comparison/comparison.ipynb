{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d02c9e-cf18-480b-b45d-9e8b3a94a2af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from datasets import *\n",
    "from pyvenn import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fe09f-3b65-4d4a-93a8-5b1515f3087e",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d97bdf-9287-4376-a918-5480d6569c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_validation_dataset(dataset_name):\n",
    "    dataset=load_from_disk(f'../defects4j_validation/dataset_validated/{dataset_name}')\n",
    "    print(f' \\n==========\\n{dataset_name}\\n==========\\n',dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeb20b6-8613-457f-834b-42c94aa9cb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "==========\n",
      "codellama_vanilla\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "codellama_classinfo\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "codellama_classinfo_lora\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "codellama_no_classinfo_lora\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "repairllama\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "repairllama_classinfo\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "repairllama_classinfo_lora\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n",
      " \n",
      "==========\n",
      "repairllama_paper\n",
      "==========\n",
      " Dataset({\n",
      "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'bug_id', 'start_line', 'end_line', 'path', 'fix_code', 'pre_context', 'post_context', 'buggy_code', 'input', 'gen', 'test_res'],\n",
      "    num_rows: 479\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "codellama_vanilla=load_validation_dataset('codellama_vanilla')\n",
    "codellama_classinfo=load_validation_dataset('codellama_classinfo')\n",
    "codellama_classinfo_lora=load_validation_dataset('codellama_classinfo_lora')\n",
    "codellama_no_classinfo_lora=load_validation_dataset('codellama_no_classinfo_lora')\n",
    "repairllama=load_validation_dataset('repairllama')\n",
    "repairllama_classinfo=load_validation_dataset('repairllama_classinfo')\n",
    "repairllama_classinfo_lora=load_validation_dataset('repairllama_classinfo_lora')\n",
    "repairllama_paper=load_validation_dataset('repairllama_paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b77dea-af07-4f7c-b142-52f18e7935fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dict={\n",
    "    'codellama_vanilla':codellama_vanilla,\n",
    "    'codellama_classinfo':codellama_classinfo,\n",
    "    'codellama_classinfo_lora':codellama_classinfo_lora,\n",
    "    'codellama_no_classinfo_lora':codellama_no_classinfo_lora,\n",
    "    'repairllama':repairllama,\n",
    "    'repairllama_classinfo':repairllama_classinfo,\n",
    "    'repairllama_classinfo_lora':repairllama_classinfo_lora,\n",
    "    'repairllama_paper':repairllama_paper,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05af08-b09b-434c-ab7e-7c5943ecdac1",
   "metadata": {},
   "source": [
    "# STATICS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6e05c-3a9c-4af3-8295-8fb9ac97b2dd",
   "metadata": {},
   "source": [
    "## correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc32b2b-eefd-4553-a24d-bf9b52c1d20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_correctness(correctness_list):\n",
    "    # 按优先级确定correctness\n",
    "    if 'plausible' in correctness_list:\n",
    "        return 'plausible'\n",
    "    elif 'wrong' in correctness_list:\n",
    "        return 'wrong'\n",
    "    elif 'uncompilable' in correctness_list:\n",
    "        return 'uncompilable'\n",
    "    else:\n",
    "        return 'timeout'  # 如果列表中没有已知的correctness值\n",
    "\n",
    "def statistics_by_correctness(dataset):\n",
    "    # 初始化一个字典来临时存储每个bug_id的所有correctness值\n",
    "    temp_result = {}\n",
    "    # 初始化最终结果字典\n",
    "    final_result = {}\n",
    "\n",
    "    # 收集每个bug_id的所有correctness值\n",
    "    for row in dataset:\n",
    "        bug_id = row['bug_id']\n",
    "        test_res_list = row['test_res']  # 这是一个列表，不是单个字典\n",
    "        if not test_res_list:\n",
    "            continue\n",
    "        if bug_id not in temp_result:\n",
    "            temp_result[bug_id] = []\n",
    "        # 遍历test_res_list中的每个字典\n",
    "        for test_res in test_res_list:\n",
    "            correctness = test_res['correctness']\n",
    "            temp_result[bug_id].append(correctness)\n",
    "\n",
    "    # 确定每个bug_id的最终correctness并组织最终结果\n",
    "    for bug_id, correctness_list in temp_result.items():\n",
    "        final_correctness = determine_correctness(correctness_list)\n",
    "        if final_correctness not in final_result:\n",
    "            final_result[final_correctness] = []\n",
    "        final_result[final_correctness].append(bug_id)\n",
    "\n",
    "    return final_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327008ee-ce5a-4873-9c86-bce931758e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========codellama_vanilla=========\n",
      "plausible: 116\n",
      "wrong: 238\n",
      "uncompilable: 119\n",
      "timeout or error 6\n",
      "=========codellama_classinfo=========\n",
      "plausible: 87\n",
      "wrong: 274\n",
      "uncompilable: 113\n",
      "timeout or error 5\n",
      "=========codellama_classinfo_lora=========\n",
      "plausible: 87\n",
      "wrong: 284\n",
      "uncompilable: 102\n",
      "timeout or error 6\n",
      "=========codellama_no_classinfo_lora=========\n",
      "plausible: 86\n",
      "wrong: 269\n",
      "uncompilable: 119\n",
      "timeout or error 5\n",
      "=========repairllama=========\n",
      "plausible: 114\n",
      "wrong: 254\n",
      "uncompilable: 106\n",
      "timeout or error 5\n",
      "=========repairllama_classinfo=========\n",
      "plausible: 114\n",
      "wrong: 255\n",
      "uncompilable: 104\n",
      "timeout or error 6\n",
      "=========repairllama_classinfo_lora=========\n",
      "plausible: 97\n",
      "wrong: 261\n",
      "uncompilable: 116\n",
      "timeout or error 5\n",
      "=========repairllama_paper=========\n",
      "plausible: 150\n",
      "wrong: 254\n",
      "uncompilable: 70\n",
      "timeout or error 5\n"
     ]
    }
   ],
   "source": [
    "res_dict={}\n",
    "for name in dataset_dict:\n",
    "    print(f'========={name}=========')\n",
    "    dataset= dataset_dict[name]\n",
    "    res=statistics_by_correctness(dataset)\n",
    "    lst=['plausible','wrong','uncompilable']\n",
    "    s=0\n",
    "    for i in lst:\n",
    "        print(f'{i}:', len(res[i]))\n",
    "        s+=len(res[i])\n",
    "    print('timeout or error', 479-s)\n",
    "    res_dict[name]=res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a5350-92ec-4be2-902d-25bf5998c2f5",
   "metadata": {},
   "source": [
    "## length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b34e582-536e-4475-8360-6d1e20689160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========codellama_vanilla=========\n",
      "average patch length 174.16966363444044\n",
      "=========codellama_classinfo=========\n",
      "average patch length 199.437156157427\n",
      "=========codellama_classinfo_lora=========\n",
      "average patch length 54.74960594460707\n",
      "=========codellama_no_classinfo_lora=========\n",
      "average patch length 81.9032400264492\n",
      "=========repairllama=========\n",
      "average patch length 147.90901231899718\n",
      "=========repairllama_classinfo=========\n",
      "average patch length 169.2356182499449\n",
      "=========repairllama_classinfo_lora=========\n",
      "average patch length 49.2953125\n",
      "=========repairllama_paper=========\n",
      "average patch length 156.5341963322546\n"
     ]
    }
   ],
   "source": [
    "def average_patch_length(dataset):\n",
    "    # 初始化累计变量和计数器\n",
    "    total_length = 0\n",
    "    count = 0\n",
    "\n",
    "    # 遍历数据集\n",
    "    for row in dataset:\n",
    "        # 获取每个bug_id对应的test_res列表\n",
    "        test_res_list = row['test_res']\n",
    "        if not test_res_list:\n",
    "            continue\n",
    "        # 遍历test_res列表中的每个字典\n",
    "        for test_res in test_res_list:\n",
    "            # 获取patch并累计其长度\n",
    "            patch = test_res['patch']\n",
    "            total_length += len(patch)\n",
    "            count += 1\n",
    "\n",
    "    # 计算平均长度，避免除以零的错误\n",
    "    average_length = total_length / count if count > 0 else 0\n",
    "    return average_length\n",
    "\n",
    "\n",
    "# 调用函数并打印结果\n",
    "for name in dataset_dict:\n",
    "    print(f'========={name}=========')\n",
    "    dataset= dataset_dict[name]\n",
    "    avg_length=average_patch_length(dataset)\n",
    "    print('average patch length', avg_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a3836-5152-42f9-9ff6-a469a3a0c859",
   "metadata": {},
   "source": [
    "## similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ed8f66-cc84-476c-9507-1c393d15d0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    s1, s2=s1.strip(), s2.strip()\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def similarity_score(distance, max_length):\n",
    "    if max_length == 0:\n",
    "        return 1.0  # 假设两个空字符串是完全相似的\n",
    "    return 1 - (distance / max_length)\n",
    "\n",
    "def average_patch_similarity(dataset):\n",
    "    similarity_results = {}\n",
    "    all_scores = []\n",
    "\n",
    "    for row in tqdm(dataset):\n",
    "        bug_id = row['bug_id']\n",
    "        test_res_list = row['test_res']\n",
    "        \n",
    "        if not test_res_list:\n",
    "            continue\n",
    "            \n",
    "        scores = []\n",
    "\n",
    "        for i in range(len(test_res_list)):\n",
    "            for j in range(i+1, len(test_res_list)):\n",
    "                patch1 = test_res_list[i]['patch']\n",
    "                patch2 = test_res_list[j]['patch']\n",
    "                max_length = max(len(patch1), len(patch2))\n",
    "                distance = levenshtein_distance(patch1, patch2)\n",
    "                score = similarity_score(distance, max_length)\n",
    "                scores.append(score)\n",
    "\n",
    "        # 计算并存储平均相似度分数\n",
    "        if scores:\n",
    "            average_score = sum(scores) / len(scores)\n",
    "            similarity_results[bug_id] = average_score\n",
    "            all_scores.extend(scores)  # 将所有得分添加到总列表中，以计算整个数据集的平均相似度\n",
    "        else:\n",
    "            similarity_results[bug_id] = 1.0  # 如果只有一个patch，假设相似度为100%\n",
    "\n",
    "    # 计算整个数据集的平均相似度\n",
    "    dataset_average_similarity = sum(all_scores) / len(all_scores) if all_scores else 1.0\n",
    "    return similarity_results, dataset_average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df7e866-1fcb-409e-b1ef-59465e5e0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========codellama_vanilla=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [07:41<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 55.38%\n",
      "=========codellama_classinfo=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [10:24<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 46.35%\n",
      "=========codellama_classinfo_lora=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [00:28<00:00, 16.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 45.27%\n",
      "=========codellama_no_classinfo_lora=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [01:53<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 48.30%\n",
      "=========repairllama=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [06:17<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 51.49%\n",
      "=========repairllama_classinfo=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [07:09<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 51.85%\n",
      "=========repairllama_classinfo_lora=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [00:20<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 42.36%\n",
      "=========repairllama_paper=========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [08:43<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Average Similarity Score = 53.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 调用函数并打印结果\n",
    "for name in dataset_dict:\n",
    "    print(f'========={name}=========')\n",
    "    dataset= dataset_dict[name]\n",
    "    sim_res, avg_sim=average_patch_similarity(dataset)\n",
    "    print(f\"Dataset Average Similarity Score = {avg_sim:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c02203-e1c7-41b3-9921-addc4c7f79db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_patch_list_similarity(listA, listB):\n",
    "    max_similarity = 0\n",
    "    for patchA in listA:\n",
    "        for patchB in listB:\n",
    "            distance = levenshtein_distance(patchA, patchB)\n",
    "            max_length = max(len(patchA), len(patchB))\n",
    "            similarity = similarity_score(distance, max_length)\n",
    "            max_similarity = max(max_similarity, similarity)\n",
    "    return max_similarity\n",
    "\n",
    "def compare_datasets(dataset_dict, base_dataset_name='codellama_vanilla'):\n",
    "    results = {}\n",
    "    base_dataset = dataset_dict[base_dataset_name]\n",
    "\n",
    "    for dataset_name, dataset in dataset_dict.items():\n",
    "        if dataset_name == base_dataset_name:\n",
    "            continue  # Skip comparing the dataset with itself\n",
    "        print(f'{dataset_name} start!')\n",
    "        \n",
    "        results[dataset_name] = {}\n",
    "        for sample in base_dataset:\n",
    "            bug_id = sample['bug_id']\n",
    "            test_res = sample['test_res']\n",
    "            if not test_res:\n",
    "                continue\n",
    "                \n",
    "            sampleB = dataset.filter(lambda x:x['bug_id']==bug_id)[0]\n",
    "            \n",
    "            listA = [test_res['patch'] for test_res in test_res]\n",
    "            test_resB=sampleB['test_res']\n",
    "            if not test_resB:\n",
    "                continue\n",
    "            listB=[]\n",
    "\n",
    "            for res in test_resB:\n",
    "                if res['correctness']=='plausible':\n",
    "                    listB.append(res['patch'])\n",
    "                    \n",
    "            if not listB:\n",
    "                continue\n",
    "                \n",
    "            similarity = max_patch_list_similarity(listA, listB)\n",
    "            results[dataset_name][bug_id] = similarity\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 调用函数并打印结果\n",
    "dataset_sim = compare_datasets(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0fe8e49-b544-4cc5-9566-d9af609f82af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codellama_classinfo avg sim score:0.8457298398404217\n",
      "codellama_classinfo_lora avg sim score:0.7940045907064501\n",
      "codellama_no_classinfo_lora avg sim score:0.8247297603699361\n",
      "repairllama avg sim score:0.8517089833743694\n",
      "repairllama_classinfo avg sim score:0.8138774788569407\n",
      "repairllama_classinfo_lora avg sim score:0.7796504763810237\n",
      "repairllama_paper avg sim score:0.8034998668012293\n"
     ]
    }
   ],
   "source": [
    "for dataset, sim_dict in dataset_sim.items():\n",
    "    sim_list=[]\n",
    "    for bug_id, sim_score in sim_dict.items():\n",
    "        sim_list.append(sim_score)\n",
    "    print(f'{dataset} avg sim score:{sum(sim_list)/len(sim_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b896931-ad20-41f5-850c-3762da5008fd",
   "metadata": {},
   "source": [
    "## same patch analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba0cd528-917b-4e49-bd66-e660dc48d15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "not_sim_bug_ids_dict={}\n",
    "for dataset_name, similarities in dataset_sim.items():\n",
    "    sim_thershold=0.5\n",
    "    for bug_id, similarity_score in similarities.items():\n",
    "        if similarity_score <= sim_thershold:\n",
    "            if dataset_name not in not_sim_bug_ids_dict:\n",
    "                not_sim_bug_ids_dict[dataset_name]=[]\n",
    "            else:\n",
    "                not_sim_bug_ids_dict[dataset_name].append(bug_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0575b-0e1f-4228-93d7-fbf916c37416",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_sim_bug_ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79a66084-a340-4454-b64f-2bc1302c4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_name='codellama_classinfo_lora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb0973-ae9a-4d8c-8653-46cecd6a1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in dataset_dict.items():\n",
    "    if name=='codellama_vanilla':\n",
    "        continue\n",
    "    if name!=check_name:\n",
    "        continue    \n",
    "    \n",
    "    print(f'======{name}=======')\n",
    "    for sample in dataset:\n",
    "        bug_id=sample['bug_id']\n",
    "        not_sim_lst=not_sim_bug_ids_dict[name]\n",
    "        if bug_id in not_sim_lst:\n",
    "            print(f\"\\n====={bug_id}=====\\n\")\n",
    "            print(sample['input'])\n",
    "            print('fix: ', sample['fix_code'])\n",
    "            print('model generated patch:\\n')\n",
    "            for i in sample['test_res']:\n",
    "                if i['correctness']=='plausible':\n",
    "                    print('------------------')\n",
    "                    print(i['patch'])\n",
    "            codellama_sample=codellama_vanilla.filter(lambda x:x['bug_id']==bug_id)[0]\n",
    "            print('codellama generated patch:\\n')\n",
    "            for i in sample['test_res']:\n",
    "                print('------------------')\n",
    "                print(i['patch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b85a6f-e23f-4fa8-a70b-2afe1505fea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in repairllama_paper:\n",
    "    bug_id=sample['bug_id']\n",
    "    if bug_id in sim_bug_ids:\n",
    "        print(f\"\\n====={bug_id}=====\\n\")\n",
    "        print(sample['input'])\n",
    "        print('fix: ', sample['fix_code'])\n",
    "        for i in sample['test_res']:\n",
    "            if i['correctness']=='plausible':\n",
    "                print('------------------')\n",
    "                print(i['patch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47974743-e701-4511-9ddf-ed805eb25f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PATCH analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b6a3c-0266-4004-9a8f-7bca27abd34a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## codellama vanilla pluasible patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309358a-2043-4fe0-a412-b4ac03da5660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in codellama_vanilla:\n",
    "    if not sample['test_res']:\n",
    "        continue\n",
    "    is_plausible=len([i for i in sample['test_res'] if i['correctness']=='plausible']) > 0\n",
    "    if is_plausible:\n",
    "        bug_id=sample['bug_id']\n",
    "        print(f\"\\n====={bug_id}=====\\n\")\n",
    "        print(sample['input'])\n",
    "        print('fix: ', sample['fix_code'])\n",
    "\n",
    "        for i in sample['test_res']:\n",
    "            if i['correctness']=='plausible':\n",
    "                print('------------------')\n",
    "                print(i['patch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c36e5-84c0-4b62-81ed-895b128f3eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## unique bug_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32577230-5301-4b91-8a7d-23727e84d6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'codellama_vanilla': ['Csv-14', 'Compress-41', 'Chart-10', 'Closure-78', 'Mockito-22', 'Compress-26', 'Closure-58', 'Lang-37'], 'codellama_classinfo': ['JacksonXml-4', 'Lang-40'], 'codellama_classinfo_lora': ['Closure-109', 'Lang-38'], 'codellama_no_classinfo_lora': ['Jsoup-49'], 'repairllama': ['Closure-65', 'Time-18'], 'repairllama_classinfo': ['JacksonDatabind-24', 'Lang-16', 'JacksonDatabind-39', 'Lang-55'], 'repairllama_classinfo_lora': ['Math-105', 'Codec-2'], 'repairllama_paper': ['Compress-15', 'Time-20', 'Closure-77', 'Jsoup-80', 'Math-69', 'Compress-7', 'Mockito-29', 'JacksonDatabind-93', 'Jsoup-70', 'Jsoup-85']}\n"
     ]
    }
   ],
   "source": [
    "def find_unique_plausible_ids(res_dict):\n",
    "    # 初始化一个字典来存储最终结果\n",
    "    unique_plausible_ids = {dataset: [] for dataset in res_dict}\n",
    "\n",
    "    # 遍历每个数据集，找到每个数据集中的plausible bug_id\n",
    "    for dataset, correctness_dict in res_dict.items():\n",
    "        plausible_ids = correctness_dict.get('plausible', [])\n",
    "        \n",
    "        # 对于每个plausible的bug_id，检查它是否在其他数据集中出现过\n",
    "        for bug_id in plausible_ids:\n",
    "            is_unique = True  # 假设当前bug_id是唯一的，直到证明它在其他数据集中出现过\n",
    "            \n",
    "            # 检查其他数据集\n",
    "            for other_dataset, other_correctness_dict in res_dict.items():\n",
    "                if dataset == other_dataset:\n",
    "                    continue  # 跳过当前正在检查的数据集\n",
    "                # 如果bug_id在其他数据集的任何correctness下出现，则不是唯一的\n",
    "                if any(bug_id in ids for ids in other_correctness_dict['plausible']):\n",
    "                    is_unique = False\n",
    "                    break  # 一旦找到重复项，就停止检查当前bug_id\n",
    "            \n",
    "            # 如果当前bug_id是唯一的，则添加到结果字典中\n",
    "            if is_unique:\n",
    "                unique_plausible_ids[dataset].append(bug_id)\n",
    "\n",
    "    return unique_plausible_ids\n",
    "\n",
    "\n",
    "# 调用函数并打印结果\n",
    "unique_plausible_ids = find_unique_plausible_ids(res_dict)\n",
    "print(unique_plausible_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c58b3-48d1-4d1d-8b0d-aa277646a6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('unique bug_id results')\n",
    "for name in unique_plausible_ids:\n",
    "    id_lst=unique_plausible_ids[name]\n",
    "    dataset=dataset_dict[name]\n",
    "    \n",
    "    print(f'========={name}=========')\n",
    "    for ids in id_lst:\n",
    "        sample=dataset.filter(lambda x:x['bug_id']==ids)[0]\n",
    "        print(f'====={ids}=====')\n",
    "        print(sample['input'])\n",
    "        print('fix: ', sample['fix_code'])\n",
    "        for i in sample['test_res']:\n",
    "            del i['test_message']\n",
    "            if i['correctness']=='plausible':\n",
    "                print('-----------------')\n",
    "                print(i['patch'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec06ca-a869-48a9-bfcd-8d4b92bfbf48",
   "metadata": {},
   "source": [
    "# repairllama check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5b09585-972b-486f-bce0-a8ab838a99b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/17988/.cache/huggingface/datasets/json/default-bfbb90bc52752341/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    }
   ],
   "source": [
    "repairllama_result=load_dataset('json', data_files='/Users/17988/PycharmProjects/repairllama/results/defects4j/repairllama/lora/RepairLLaMA_defects4j_f2f_bugs_results_ir4_or2.jsonl', split='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "babd04d6-93f2-4e6f-ba4c-72d33c562696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plausible_id_list=[]\n",
    "for sample in repairllama_result:\n",
    "    bug_id, res=sample['bug_id'], sample['test_results']\n",
    "    if 'Line match' in res or 'Plausible' in res or 'AST match' in res:\n",
    "        plausible_id_list.append(bug_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36f0340c-d64c-405a-a6c9-605a34eca388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plausible_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deeead8-b185-4cd5-8231-dc4632b161a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in repairllama_paper:\n",
    "    bug_id, res=sample['bug_id'], sample['test_res']\n",
    "    if bug_id in plausible_id_list:\n",
    "        different=True\n",
    "        for patch in res:\n",
    "            if patch['correctness']=='plausible':\n",
    "                different=False\n",
    "                break\n",
    "        if different:\n",
    "            print(sample['input'])\n",
    "            print('fix: ', sample['fix_code'])\n",
    "            for i in res:\n",
    "                del i['test_message']\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b84a6-4bd6-4088-b839-d70f36ab4c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
