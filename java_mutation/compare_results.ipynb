{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff257cf-8a93-442b-8017-a2240238cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d9fc5-5b09-4468-9a89-ce1a2209e539",
   "metadata": {},
   "source": [
    "## 加载结果数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b19e20-0de8-46ca-94c0-3feeb03c58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/alex.wu/.cache/huggingface/datasets/json/default-086715474a996e88/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935d3af3a60244839589a8a138dbd8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## repairllama\n",
    "file_path='/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/repairllama/lora/RepairLLaMA_defects4j_f2f_bugs_results_ir4_or2.jsonl'\n",
    "repairllama_dataset=load_dataset('json', data_files=file_path)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd30a04-eca7-4377-80c5-1e7220d89508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function name_map at 0x7ff4c81d8310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ours\n",
    "\n",
    "ours_dataset=load_from_disk('/Users/alex.wu/PycharmProjects/apr_datasets_processing/defects4j_validation/dataset_validated/defects4j_context_gen_10_validation')\n",
    "\n",
    "def name_map(x):\n",
    "    x['bug_id']=x['projectName'].capitalize().replace('Jacksondatabind', 'JacksonDatabind').replace('Jacksoncore', 'JacksonCore').replace(\n",
    "            'Jacksonxml', 'JacksonXml').replace('Jxpath', 'JxPath').replace('_', '-')\n",
    "    x['gen']=[i.replace(x['input'], '').replace('<s>','').replace('</s>','').replace('<unk>','') for i in x['gen']]\n",
    "    for i in x['test_res']:\n",
    "        del i['test_message']\n",
    "    return x\n",
    "\n",
    "ours_dataset=ours_dataset.map(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242dd32e-b1a3-42f4-b06f-76b6e884ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_java_comments_correctly(code):\n",
    "    \"\"\"\n",
    "    正确地去除Java代码中的单行和多行注释，不移除注释前的换行符。\n",
    "\n",
    "    参数:\n",
    "    - code: 字符串，包含Java代码。\n",
    "\n",
    "    返回:\n",
    "    - 去除注释的代码字符串，保留其他内容不变。\n",
    "    \"\"\"\n",
    "    # 移除多行注释，这里假设多行注释不跨越多个非空白行\n",
    "    code_no_multiline_comments = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)\n",
    "    # 移除单行注释及其后的换行符，如果存在\n",
    "    cleaned_code = re.sub(r'(?m)^ *//.*\\n?', '', code_no_multiline_comments)\n",
    "\n",
    "    return cleaned_code.strip()\n",
    "\n",
    "def remove_spaces_newlines_and_get_indices(java_code):\n",
    "    cleaned_code = \"\"\n",
    "    indices = []\n",
    "    for index, char in enumerate(java_code):\n",
    "        if char not in [' ', '\\n', '\\r', '\\t']:\n",
    "            cleaned_code += char\n",
    "            indices.append(index)\n",
    "    return indices, cleaned_code\n",
    "\n",
    "def find_substring_indices(main_string, substring):\n",
    "    start_index = main_string.find(substring)\n",
    "    \n",
    "    # 如果找不到子字符串，则返回-1\n",
    "    if start_index == -1:\n",
    "        return -1, -1\n",
    "\n",
    "    end_index = start_index + len(substring) - 1\n",
    "    return start_index, end_index\n",
    "\n",
    "def replace_sub(java_code, java_patch):\n",
    "    rm_code_ind_lst, rm_java_code=remove_spaces_newlines_and_get_indices(java_code)\n",
    "    _, rm_java_patch=remove_spaces_newlines_and_get_indices(java_patch)\n",
    "    start_ind, end_ind=find_substring_indices(rm_java_code, rm_java_patch)\n",
    "    code_start_ind, code_end_ind=rm_code_ind_lst[start_ind], rm_code_ind_lst[end_ind]\n",
    "    patch=java_code[:code_start_ind]+java_code[code_end_ind+1:]\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3dbae29-e138-4f83-968c-1134883d452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(x):\n",
    "    bug_id=x['bug_id']\n",
    "    repairllama_sample=repairllama_dataset.filter(lambda x:x['bug_id']==bug_id)[0]\n",
    "    res=[]\n",
    "    for i,patch in enumerate(repairllama_sample['patches']):\n",
    "        patch=remove_java_comments_correctly(patch)\n",
    "        before_code=x['buggyInfo']['methodPreContext'] \n",
    "        after_code=x['buggyInfo']['methodPostContext'] \n",
    "        patch=replace_sub(patch, before_code)\n",
    "        patch=replace_sub(patch, after_code)\n",
    "        d={'correctness':repairllama_sample['test_results'][i].lower().replace('test fail','wrong').replace('compile fail','uncompilable'),\n",
    "          'patch':patch.strip()}\n",
    "        res.append(d)\n",
    "    x['repairllama_res']=res\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c5fad-724a-4ab8-ae3a-470150f36519",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=ours_dataset.map(unify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be0fd6-7550-489a-8c77-fbbd7dc65481",
   "metadata": {},
   "source": [
    "## repairllama 统计情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d50fa0c-666c-4f0e-9236-3dafea87f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "match={}\n",
    "ast_match={}\n",
    "plausible={}\n",
    "wrong={}\n",
    "uncompilable={}\n",
    "for i in dataset:\n",
    "    bug_id=i['bug_id']\n",
    "    res=i['repairllama_res']\n",
    "    d={}\n",
    "    for j in res:\n",
    "        key=j['correctness']\n",
    "        if key in d:\n",
    "            d[key].append(j['patch'])\n",
    "        else:\n",
    "            d[key]=[j['patch']]\n",
    "    if 'line match' in d:\n",
    "        match[bug_id]=d['line match']\n",
    "        print(f'\\n\\n==========={bug_id}================')\n",
    "        print(i['input'].split('// method to be repaired')[-1])\n",
    "        print('\\nfix: ', match[bug_id][0])\n",
    "    elif 'ast match' in d:\n",
    "        ast_match[bug_id]=d['ast match']\n",
    "    elif 'plausible' in d:\n",
    "        plausible[bug_id]=d['plausible']\n",
    "    elif 'wrong' in d:\n",
    "        wrong[bug_id]=d['wrong']\n",
    "    elif 'uncompilable' in d:\n",
    "        uncompilable[bug_id]=d['uncompilable']\n",
    "        \n",
    "print(len(match))\n",
    "print(len(plausible))\n",
    "print(len(wrong))\n",
    "print(len(uncompilable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f27b089-5ec8-4eaa-ba6d-29883d5c48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_line_number(match):\n",
    "    line_lst=[]\n",
    "    for i in match.values():\n",
    "        line_lst+=i\n",
    "    len_lst=[len(i.split('\\n')) for i in line_lst]\n",
    "    return sum(len_lst)/len(len_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20d96e6a-33f7-4da7-a1e4-321260f87c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7469879518072289"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_line_number(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "07e0d427-3326-4d5f-9bac-118bb3286380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4269058295964125\n",
      "2.939521800281294\n"
     ]
    }
   ],
   "source": [
    "repair_lst=[]\n",
    "v1_lst=[]\n",
    "for i in dataset:\n",
    "    for j in i['repairllama_res']:\n",
    "        repair_lst.append(j['patch'])\n",
    "    for j in i['test_res']:\n",
    "        v1_lst.append(j['patch'])  \n",
    "len_repair_lst=[len(i.split('\\n')) for i in repair_lst]\n",
    "len_v1_lst=[len(i.split('\\n')) for i in v1_lst]\n",
    "print(sum(len_repair_lst)/len(len_repair_lst))\n",
    "print(sum(len_v1_lst)/len(len_v1_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37895651-2fab-4437-8e07-aefd00f2d109",
   "metadata": {},
   "source": [
    "## ours 统计情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5dcb47ca-29d7-4520-8061-83f0b0f4367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "127\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "ours_plausible={}\n",
    "ours_wrong={}\n",
    "ours_uncompilable={}\n",
    "for i in dataset:\n",
    "    bug_id=i['bug_id']\n",
    "    res=i['test_res']\n",
    "    d={}\n",
    "    for j in res:\n",
    "        key=j['correctness']\n",
    "        if key in d:\n",
    "            d[key].append(j['patch'])\n",
    "        else:\n",
    "            d[key]=[j['patch']]\n",
    "\n",
    "    if 'plausible' in d:\n",
    "        ours_plausible[bug_id]=d['plausible']\n",
    "        # print(f'-----{bug_id}------')\n",
    "        # print('fix: ', i['buggyInfo']['originalCode'])\n",
    "        # print(d['plausible'][0])\n",
    "    elif 'wrong' in d:\n",
    "        ours_wrong[bug_id]=d['wrong']\n",
    "    elif 'uncompilable' in d:\n",
    "        ours_uncompilable[bug_id]=d['uncompilable']\n",
    "        \n",
    "print(len(ours_plausible))\n",
    "print(len(ours_wrong))\n",
    "print(len(ours_uncompilable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ac30592b-7664-46eb-a6bb-399e5294842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3043478260869565"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_line_number(ours_plausible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122eeec5-f941-4bd3-8496-0438083e7652",
   "metadata": {},
   "source": [
    "## 查看利用class上下文情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9205ccb5-e572-466f-b1b1-8a25ae849411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_member_name(string):\n",
    "    return string.split(' ')[-1]\n",
    "\n",
    "def get_method_name(string):\n",
    "    return string.split('(')[0].split(' ')[0]\n",
    "\n",
    "def is_class_context_used(x, name):\n",
    "    inputs=x['input'].split('// method to be repaired\\n')[1]\n",
    "    member_lst=[get_member_name(i) for i in x['classInformation']['memberVariables']]\n",
    "    method_lst=[get_method_name(i) for i in x['classInformation']['memberMethods']]\n",
    "    \n",
    "    unused_context_lst=[i for i in member_lst+method_lst if i not in inputs]\n",
    "    \n",
    "    patches=[i['patch'] for i in x[name]]\n",
    "    for i in unused_context_lst:\n",
    "        if i in '\\n'.join(patches):\n",
    "            return True\n",
    "    return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d975bc0-0ff6-46de-aaa6-12a6c8242241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "## ours利用上下文\n",
    "class_context_used_dataset=dataset.filter(lambda x:is_class_context_used(x, 'test_res'))\n",
    "print(len(class_context_used_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0fd2ca40-5cf2-473a-9500-9747ffdebab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'input', 'output', 'gen', 'test_res', 'bug_id', 'repairllama_res'],\n",
       "    num_rows: 28\n",
       "})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_context_used_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "13f94bfa-0124-4c05-b83c-9f42c3da5bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "## repairllama利用上下文 \n",
    "print(len(dataset.filter(lambda x:is_class_context_used(x, 'repairllama_res'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b63da0-c1b0-48cb-aa99-44eb3568781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in class_context_used_dataset:\n",
    "    bug_id=sample['bug_id']\n",
    "    res=sample['test_res']\n",
    "    fix=sample['buggyInfo']['originalCode']\n",
    "    print(f'==========={bug_id}================')\n",
    "    print(sample['input'])\n",
    "    print('fix: ', fix)\n",
    "    print('---ours repair------')\n",
    "    for i in res:\n",
    "        print(i)\n",
    "    print('---repairllama------')\n",
    "    for i in sample['repairllama_res']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65700bdd-8bba-4a7a-acbb-b85b57c27bd6",
   "metadata": {},
   "source": [
    "## 查看整体patch情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e9d0f-5e06-446c-b97a-0173301bedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    bug_id=sample['bug_id']\n",
    "    res=sample['test_res']\n",
    "    fix=sample['buggyInfo']['originalCode']\n",
    "    print(f'==========={bug_id}================')\n",
    "    print(sample['input'])\n",
    "    print('fix: ', fix)\n",
    "    print('---ours repair------')\n",
    "    for i in res:\n",
    "        print(i)\n",
    "    print('---repairllama------')\n",
    "    for i in sample['repairllama_res']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118c1a82-2dbc-4761-9cca-445841125821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter(lambda x:x['bug_id']=='Cli-4')[0]['gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b407d0-8439-41b2-b9d3-f43adcef7b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
