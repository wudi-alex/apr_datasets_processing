{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f092ba73-0a86-4cc3-9e97-4d921818fc1c",
   "metadata": {},
   "source": [
    "## list defects4j projects used by repairllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6c8746b-ae65-43f4-8529-a9d90a16a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_subfolders(directory):\n",
    "    \"\"\"列出指定目录下所有子文件夹的名称\"\"\"\n",
    "    subfolders = [f.name for f in os.scandir(directory) if f.is_dir()]\n",
    "    return subfolders\n",
    "\n",
    "# 使用示例\n",
    "directory_path = '/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/repairllama/fft/patches'\n",
    "# directory_path = '/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/codellama/patches'\n",
    "subfolders = list_subfolders(directory_path)\n",
    "print(len(subfolders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b25a42-6196-4d65-8ccf-fa99d3d04b89",
   "metadata": {},
   "source": [
    "## find the patch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bffa6b3b-22a7-4446-8e62-58f4ca5e4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path_file(project_id):\n",
    "    project, number=project_id.split('-')[0], project_id.split('-')[1]\n",
    "    base_path='/Users/alex.wu/defects4j/framework/projects'\n",
    "    file_path=f'{base_path}/{project}/patches/{number}.src.patch'\n",
    "    return file_path\n",
    "\n",
    "def find_project_root_file(project_id):\n",
    "    project, number=project_id.split('-')[0].lower(), project_id.split('-')[1]\n",
    "    base_path='/Users/alex.wu/defects4j_projects_buggy'\n",
    "    file_path=f'{base_path}/{project.lower()}_{number}'\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95739853-df9c-428a-ae8f-a03beeb48141",
   "metadata": {},
   "source": [
    "## get file startline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "946ab713-8460-4b1c-b0f5-d1e4437bb91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更改开始的行号是：1797\n",
      "代码地址是：source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_line_number_and_code_path_from_diff_file(file_path):\n",
    "    \"\"\"\n",
    "    从存储在文件中的diff内容提取更改开始的行号和代码地址。\n",
    "    \n",
    "    参数:\n",
    "    - file_path: 字符串，指向包含diff的文本文件的路径。\n",
    "    \n",
    "    返回:\n",
    "    - tuple: (行号, 代码地址)。如果没有找到，返回(None, None)。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            diff_content = file.read()\n",
    "            # 使用正则表达式匹配文件路径\n",
    "            path_match = re.search(r'diff --git a/(.*?) b/', diff_content)\n",
    "            code_path = path_match.group(1) if path_match else None\n",
    "            \n",
    "            # 使用正则表达式匹配@@ -x,y +x,y @@格式以提取行号\n",
    "            line_match = re.search(r'@@ -\\d+,\\d+ \\+(\\d+),\\d+ @@', diff_content)\n",
    "            line_number = int(line_match.group(1)) + 3 if line_match else None\n",
    "            \n",
    "            return line_number, code_path\n",
    "    except FileNotFoundError:\n",
    "        print(f\"文件'{file_path}'未找到。\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件时发生错误：{e}\")\n",
    "        return None, None\n",
    "\n",
    "# 注意：这里的find_path_file函数或变量似乎未定义。请确保替换file_path为正确的diff文件路径。\n",
    "file_path = find_path_file('Chart-1')\n",
    "\n",
    "# 使用函数并打印结果\n",
    "line_number, code_path = extract_line_number_and_code_path_from_diff_file(file_path)\n",
    "if line_number is not None and code_path is not None:\n",
    "    print(f\"更改开始的行号是：{line_number}\")\n",
    "    print(f\"代码地址是：{code_path}\")\n",
    "else:\n",
    "    print(\"未能从diff中提取出行号和代码地址。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04858a30-6199-4118-b92c-d7db43b26bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到匹配的文件地址：/Users/alex.wu/defects4j_projects_buggy/chart_1/source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_file_by_tail(root_dir, tail_path):\n",
    "    \"\"\"\n",
    "    在指定的根目录下查找路径尾部匹配给定尾部路径的文件地址。\n",
    "\n",
    "    参数:\n",
    "    - root_dir: 字符串，要搜索的根目录路径。\n",
    "    - tail_path: 字符串，需要匹配的文件地址路径尾部。\n",
    "\n",
    "    返回:\n",
    "    - 完整的文件地址，如果找到匹配的文件。否则返回None。\n",
    "    \"\"\"\n",
    "    # 确保尾部路径以斜杠开头\n",
    "    if not tail_path.startswith('/'):\n",
    "        tail_path = '/' + tail_path\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            # 构造当前文件的完整路径\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            # 检查文件路径是否以指定的尾部匹配\n",
    "            if file_path.endswith(tail_path):\n",
    "                return file_path  # 返回匹配的完整文件地址\n",
    "\n",
    "    # 如果遍历了整个根目录但没有找到匹配，返回None\n",
    "    return None\n",
    "\n",
    "# 示例用法\n",
    "root_dir = '/Users/alex.wu/defects4j_projects_buggy/chart_1'  # 要搜索的根目录\n",
    "tail_path = 'source/org/jfree/chart/renderer/category/AbstractCategoryItemRenderer.java'  # 需要匹配的文件地址路径尾部\n",
    "matched_file = find_file_by_tail(root_dir, tail_path)\n",
    "\n",
    "if matched_file:\n",
    "    print(f\"找到匹配的文件地址：{matched_file}\")\n",
    "else:\n",
    "    print(\"没有找到匹配的文件。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f1ac1-e653-4a6e-ad3c-90622c357902",
   "metadata": {},
   "source": [
    "## find repairllama prompt information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88d8bb07-b075-45dc-8b88-b20c00ee2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repairllama_path_file(project_id):\n",
    "    base_path='/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/repairllama/fft/patches'\n",
    "    prompt_file_path=f'{base_path}/{project_id}/prompt.txt'\n",
    "    target_file_path=f'{base_path}/{project_id}/target.diff'\n",
    "    return prompt_file_path, target_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fdba29b-61c0-46ce-b54a-7d7d10be0401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/repairllama/fft/patches/Chart-1/prompt.txt',\n",
       " '/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/repairllama/fft/patches/Chart-1/target.diff')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_repairllama_path_file(\"Chart-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "515430b9-9779-4387-82c9-0c0dbee54cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被注释的代码块开始于第5行，结束于第9行。\n",
      "开始标记前的代码:\n",
      "     public XYDataItem addOrUpdate(Number x, Number y) {\n",
      "        if (x == null) {\n",
      "            throw new IllegalArgumentException(\"Null 'x' argument.\");\n",
      "        }\n",
      "\n",
      "结束标记后的代码:\n",
      "             XYDataItem existing = (XYDataItem) this.data.get(index);\n",
      "            try {\n",
      "                overwritten = (XYDataItem) existing.clone();\n",
      "            }\n",
      "            catch (CloneNotSupportedException e) {\n",
      "                throw new SeriesException(\"Couldn't clone XYDataItem!\");\n",
      "            }\n",
      "            existing.setY(y);\n",
      "        }\n",
      "        else {\n",
      "            if (this.autoSort) {\n",
      "                this.data.add(-index - 1, new XYDataItem(x, y));\n",
      "            }\n",
      "            else {\n",
      "                this.data.add(new XYDataItem(x, y));\n",
      "            }\n",
      "            if (getItemCount() > this.maximumItemCount) {\n",
      "                this.data.remove(0);\n",
      "            }\n",
      "        }\n",
      "        fireSeriesChanged();\n",
      "        return overwritten;\n",
      "    }\n",
      "\n",
      "被注释的代码:\n",
      " XYDataItem overwritten = null;\n",
      "       int index = indexOf(x);\n",
      "       if (index >= 0 && !this.allowDuplicateXValues) {\n"
     ]
    }
   ],
   "source": [
    "def find_and_extract_code_blocks(file_path, start_marker=\"// buggy code\", end_marker=\"<FILL_ME>\"):\n",
    "    \"\"\"\n",
    "    在文件中查找特定注释代码块的开始行数和结束行数，并提取相关代码段。\n",
    "\n",
    "    参数:\n",
    "    - file_path: 字符串，指向文本文件的路径。\n",
    "    - start_marker: 字符串，标记注释代码块开始的注释内容。\n",
    "    - end_marker: 字符串，标记注释代码块结束的内容。\n",
    "\n",
    "    返回:\n",
    "    - tuple: 包含开始行数、结束行数、开始标记前的代码字符串、结束标记后的代码字符串、被注释的代码字符串。\n",
    "             如果未找到，相应位置返回None。\n",
    "    \"\"\"\n",
    "    start_line = None\n",
    "    end_line = None\n",
    "    pre_code = \"\"  # 开始标记前的代码\n",
    "    post_code = \"\"  # 结束标记后的代码\n",
    "    commented_code = \"\"  # 被注释的代码\n",
    "    in_commented_block = False\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if start_marker in line:\n",
    "                start_line = i + 1  # 文件行数从1开始\n",
    "                in_commented_block = True\n",
    "                continue\n",
    "            if end_marker in line:\n",
    "                end_line = i + 1  # 结束行的处理稍有不同\n",
    "                in_commented_block = False\n",
    "                # 继续累积post_code，直到文件结束\n",
    "                continue\n",
    "            if in_commented_block:\n",
    "                commented_code += line\n",
    "            elif end_line is not None:\n",
    "                post_code += line\n",
    "            else:\n",
    "                pre_code += line\n",
    "\n",
    "    return start_line, end_line, pre_code, post_code, commented_code.replace('// ', '').strip()\n",
    "\n",
    "# 将这里的文件路径替换为你的实际文件路径\n",
    "file_path = find_repairllama_path_file(\"Chart-5\")[0]\n",
    "\n",
    "# 使用函数并打印结果\n",
    "start_line, end_line, pre_code, post_code, commented_code = find_and_extract_code_blocks(file_path)\n",
    "if start_line is not None and end_line is not None:\n",
    "    print(f\"被注释的代码块开始于第{start_line}行，结束于第{end_line}行。\")\n",
    "    print(\"开始标记前的代码:\\n\", pre_code)\n",
    "    print(\"结束标记后的代码:\\n\", post_code)\n",
    "    print(\"被注释的代码:\\n\", commented_code)\n",
    "else:\n",
    "    print(\"未找到指定的被注释代码块。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77991ee4-beb2-4d5f-8f6e-96ea612d6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diff_file(file_path):\n",
    "    \"\"\"\n",
    "    从diff文件中提取修改后的内容，去除不需要的diff标记和删除的内容。\n",
    "\n",
    "    参数:\n",
    "    - file_path: 字符串，指向diff文件的路径。\n",
    "\n",
    "    返回:\n",
    "    - processed_content: 字符串，处理后的文件内容。\n",
    "    \"\"\"\n",
    "    processed_lines = []  # 存储处理后的行\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # 跳过不需要的行\n",
    "                if line.startswith('--- ') or line.startswith('+++ ') or line.startswith('@@ '):\n",
    "                    continue\n",
    "                elif line.startswith('-'):\n",
    "                    continue\n",
    "                # 移除以+开头的行的+符号\n",
    "                elif line.startswith('+'):\n",
    "                    processed_lines.append(' '+line[1:])\n",
    "                else:\n",
    "                    processed_lines.append(line)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"文件'{file_path}'未找到。\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"读取文件时发生错误：{e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # 合并处理后的行为一个字符串并返回\n",
    "    processed_content = ''.join(processed_lines)\n",
    "    return processed_content\n",
    "\n",
    "# 使用示例\n",
    "file_path = find_repairllama_path_file('Chart-4')[1]  # 将这里的路径替换为你的实际文件路径\n",
    "\n",
    "# 调用函数并打印结果\n",
    "processed_content = process_diff_file(file_path)\n",
    "print(processed_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee10a37-e847-41b6-8594-32feb78d2447",
   "metadata": {},
   "source": [
    "## 构建info jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50da9d4b-e48e-4b91-9b98-872afde29fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public class HelloWorld {\n",
      "    public static void main(String[] args) {\n",
      "        System.out.println(\"Hello, world!\");\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_java_comments_correctly(code):\n",
    "    \"\"\"\n",
    "    正确地去除Java代码中的单行和多行注释，不移除注释前的换行符。\n",
    "\n",
    "    参数:\n",
    "    - code: 字符串，包含Java代码。\n",
    "\n",
    "    返回:\n",
    "    - 去除注释的代码字符串，保留其他内容不变。\n",
    "    \"\"\"\n",
    "    # 移除多行注释，这里假设多行注释不跨越多个非空白行\n",
    "    code_no_multiline_comments = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)\n",
    "    # 移除单行注释及其后的换行符，如果存在\n",
    "    cleaned_code = re.sub(r'(?m)^ *//.*\\n?', '', code_no_multiline_comments)\n",
    "\n",
    "    return cleaned_code.strip()\n",
    "\n",
    "# 示例Java代码字符串\n",
    "java_code = \"\"\"\n",
    "public class HelloWorld {\n",
    "    public static void main(String[] args) {\n",
    "        // 这是单行注释\n",
    "        System.out.println(\"Hello, world!\");\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 使用函数并打印结果\n",
    "cleaned_code = remove_java_comments_correctly(java_code)\n",
    "print(cleaned_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61072514-af24-4e3d-b552-fe08d16a7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces_newlines_and_get_indices(java_code):\n",
    "    cleaned_code = \"\"\n",
    "    indices = []\n",
    "    for index, char in enumerate(java_code):\n",
    "        if char not in [' ', '\\n', '\\r', '\\t']:\n",
    "            cleaned_code += char\n",
    "            indices.append(index)\n",
    "    return indices, cleaned_code\n",
    "\n",
    "def find_substring_indices(main_string, substring):\n",
    "    start_index = main_string.find(substring)\n",
    "    \n",
    "    # 如果找不到子字符串，则返回-1\n",
    "    if start_index == -1:\n",
    "        return -1, -1\n",
    "\n",
    "    end_index = start_index + len(substring) - 1\n",
    "    return start_index, end_index\n",
    "\n",
    "def replace_sub(java_code, java_patch):\n",
    "    rm_code_ind_lst, rm_java_code=remove_spaces_newlines_and_get_indices(java_code)\n",
    "    _, rm_java_patch=remove_spaces_newlines_and_get_indices(java_patch)\n",
    "    start_ind, end_ind=find_substring_indices(rm_java_code, rm_java_patch)\n",
    "    code_start_ind, code_end_ind=rm_code_ind_lst[start_ind], rm_code_ind_lst[end_ind]\n",
    "    patch=java_code[:code_start_ind]+java_code[code_end_ind+1:]\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a7b5213-c41e-4b4b-aa61-aedb72d9eb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startLine': 4493,\n",
       " 'filePath': '/Users/alex.wu/defects4j_projects_buggy/chart_4/source/org/jfree/chart/plot/XYPlot.java',\n",
       " 'mutationStrategy': 'RELATIONAL_EXPRESSION_MUTATION',\n",
       " 'projectName': 'chart_4',\n",
       " 'endLine': 4501,\n",
       " 'methodPreContext': '    public Range getDataRange(ValueAxis axis) {\\n        Range result = null;\\n        List mappedDatasets = new ArrayList();\\n        List includedAnnotations = new ArrayList();\\n        boolean isDomainAxis = true;\\n        int domainIndex = getDomainAxisIndex(axis);\\n        if (domainIndex >= 0) {\\n            isDomainAxis = true;\\n            mappedDatasets.addAll(getDatasetsMappedToDomainAxis(\\n                    new Integer(domainIndex)));\\n            if (domainIndex == 0) {\\n                Iterator iterator = this.annotations.iterator();\\n                while (iterator.hasNext()) {\\n                    XYAnnotation annotation = (XYAnnotation) iterator.next();\\n                    if (annotation instanceof XYAnnotationBoundsInfo) {\\n                        includedAnnotations.add(annotation);\\n                    }\\n                }\\n            }\\n        }\\n        int rangeIndex = getRangeAxisIndex(axis);\\n        if (rangeIndex >= 0) {\\n            isDomainAxis = false;\\n            mappedDatasets.addAll(getDatasetsMappedToRangeAxis(\\n                    new Integer(rangeIndex)));\\n            if (rangeIndex == 0) {\\n                Iterator iterator = this.annotations.iterator();\\n                while (iterator.hasNext()) {\\n                    XYAnnotation annotation = (XYAnnotation) iterator.next();\\n                    if (annotation instanceof XYAnnotationBoundsInfo) {\\n                        includedAnnotations.add(annotation);\\n                    }\\n                }\\n            }\\n        }\\n        Iterator iterator = mappedDatasets.iterator();\\n        while (iterator.hasNext()) {\\n            XYDataset d = (XYDataset) iterator.next();\\n            if (d != null) {\\n                XYItemRenderer r = getRendererForDataset(d);\\n                if (isDomainAxis) {\\n                    if (r != null) {\\n                        result = Range.combine(result, r.findDomainBounds(d));\\n                    }\\n                    else {\\n                        result = Range.combine(result,\\n                                DatasetUtilities.findDomainBounds(d));\\n                    }\\n                }\\n                else {\\n                    if (r != null) {\\n                        result = Range.combine(result, r.findRangeBounds(d));\\n                    }\\n                    else {\\n                        result = Range.combine(result,\\n                                DatasetUtilities.findRangeBounds(d));\\n                    }\\n                }\\n',\n",
       " 'methodPostContext': '            }\\n        }\\n        Iterator it = includedAnnotations.iterator();\\n        while (it.hasNext()) {\\n            XYAnnotationBoundsInfo xyabi = (XYAnnotationBoundsInfo) it.next();\\n            if (xyabi.getIncludeInDataBounds()) {\\n                if (isDomainAxis) {\\n                    result = Range.combine(result, xyabi.getXRange());\\n                }\\n                else {\\n                    result = Range.combine(result, xyabi.getYRange());\\n                }\\n            }\\n        }\\n        return result;\\n    }\\n',\n",
       " 'buggyCode': 'Collection c = r.getAnnotations();\\n                   Iterator i = c.iterator();\\n                   while (i.hasNext()) {\\n                       XYAnnotation a = (XYAnnotation) i.next();\\n                       if (a instanceof XYAnnotationBoundsInfo) {\\n                           includedAnnotations.add(a);\\n                       }\\n                   }',\n",
       " 'originalCode': 'if (r != null) {\\n                     Collection c = r.getAnnotations();\\n                     Iterator i = c.iterator();\\n                     while (i.hasNext()) {\\n                         XYAnnotation a = (XYAnnotation) i.next();\\n                         if (a instanceof XYAnnotationBoundsInfo) {\\n                             includedAnnotations.add(a);\\n                         }\\n                     }\\n                 }'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_info_jsonl_line(project_id):\n",
    "    json={}\n",
    "    project, number=project_id.split('-')[0].lower(), project_id.split('-')[1]\n",
    "\n",
    "    patch_file_path = find_path_file(project_id)\n",
    "    root_dir = find_project_root_file(project_id)\n",
    "    \n",
    "    file_start_line, tail_file_path = extract_line_number_and_code_path_from_diff_file(patch_file_path)\n",
    "    real_file_path = find_file_by_tail(root_dir, tail_file_path)\n",
    "    json['startLine'] = file_start_line\n",
    "    json['filePath']= real_file_path\n",
    "    json['mutationStrategy']='RELATIONAL_EXPRESSION_MUTATION'\n",
    "    json['projectName']=f'{project.lower()}_{number}'\n",
    "    \n",
    "    prompt_file_path, target_file_path = find_repairllama_path_file(project_id)\n",
    "    patch_start_line, patch_end_line, before_code, after_code, buggy_code=find_and_extract_code_blocks(prompt_file_path)\n",
    "    json['endLine'] = file_start_line + patch_end_line - patch_start_line - 1\n",
    "    json['methodPreContext'] = before_code\n",
    "    json['methodPostContext'] = after_code\n",
    "    json['buggyCode'] = buggy_code\n",
    "    \n",
    "    target=process_diff_file(target_file_path)\n",
    "    target=remove_java_comments_correctly(target)\n",
    "    target=replace_sub(target, before_code)\n",
    "    target=replace_sub(target, after_code)\n",
    "    json['originalCode'] = target.strip()\n",
    "    return json\n",
    "\n",
    "build_info_jsonl_line('Chart-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c90241-35c1-485a-9c04-ef844fde0be5",
   "metadata": {},
   "source": [
    "## 保存jsonl文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7e49e9d-70f0-42b6-ada8-e051dbcf8068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang-29 list index out of range\n",
      "Chart-7 'NoneType' object has no attribute 'startswith'\n",
      "Math-8 list index out of range\n",
      "Collections-27 list index out of range\n",
      "Collections-26 list index out of range\n",
      "Chart-23 list index out of range\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('defects4j.jsonl', 'w') as file:\n",
    "    for i in subfolders:\n",
    "        try:\n",
    "            jsonline = build_info_jsonl_line(i)\n",
    "            json_string = json.dumps(jsonline)  \n",
    "            file.write(json_string + '\\n')\n",
    "        except Exception as e:\n",
    "            print(i, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa543f3-fad0-4813-95dc-9b8c09fd86c7",
   "metadata": {},
   "source": [
    "## 保存context dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93a0fed9-2261-467e-9b65-4b2ea2f3ee9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/alex.wu/.cache/huggingface/datasets/json/default-2f08f9006d6b2262/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f1768fbfc462688284d35307cd85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd70f30cad64e2b9e2ce78666d3eb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/alex.wu/.cache/huggingface/datasets/json/default-2f08f9006d6b2262/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8aeec98c5e46d2ae6cbca76c03a7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=range(0, 448) of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to data/defects4j_context\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 步骤1: 加载JSONL文件作为Dataset\n",
    "# 假设你的JSONL文件路径为\"path/to/your/file.jsonl\"\n",
    "dataset = load_dataset('json', data_files='defects4j_with_context.jsonl')\n",
    "\n",
    "# 步骤2: 保存Dataset到磁盘\n",
    "# 指定保存路径\n",
    "output_path = 'data/defects4j_context'\n",
    "dataset.save_to_disk(output_path)\n",
    "\n",
    "print(f'Dataset saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9baa5-89e4-49b0-8952-007b85f2e137",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08914f58-8a93-4f06-bff4-340316754faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset=load_from_disk('/Users/alex.wu/PycharmProjects/apr_datasets_processing/defects4j_validation/dataset_validated/defects4j_context_gen_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5095eefa-a6d1-4a2c-be7c-ade10952f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_ids=[i.capitalize().replace('Jacksondatabind', 'JacksonDatabind').replace('Jacksoncore', 'JacksonCore').replace(\n",
    "            'Jacksonxml', 'JacksonXml').replace('Jxpath', 'JxPath').replace('_', '-') for i in dataset['projectName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2917e-0b51-4f6b-aea5-da9a443bfdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b33ba1-8236-42df-bc6d-418f61f78936",
   "metadata": {},
   "source": [
    "### repairllama result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47868be-dbd7-48c3-9ae0-4dcba3591f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='/Users/alex.wu/PycharmProjects/repairllama/results/defects4j/repairllama/lora/RepairLLaMA_defects4j_f2f_bugs_results_ir4_or2.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ebb9304-da7a-4ade-b46f-6e0df36c2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_lst=[]\n",
    "# 使用with语句打开文件，确保文件会被正确关闭\n",
    "with open(json_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # 解析每一行的JSON内容\n",
    "        json_obj = json.loads(line)\n",
    "        \n",
    "        # 处理json_obj\n",
    "        json_lst.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8b4d2c7-9489-4f50-8cba-22e97f09520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/alex.wu/.cache/huggingface/datasets/json/default-086715474a996e88/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5245b142dca74fb88804914162cd46e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repairllama_dataset=load_dataset('json', data_files=file_path)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b834f4a-567b-4103-9afe-6a1704c6e15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/480 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repairllama_dataset=repairllama_dataset.filter(lambda x:x['bug_id'] in project_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29549caf-22ca-4d7f-86c9-674ebb14c871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['bug_id', 'buggy_code', 'patches', 'test_results'],\n",
       "    num_rows: 223\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repairllama_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f09ea55-e5d9-4e4a-ba8c-f0bdbc983c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pluasible_bug_id=repairllama_dataset.filter(lambda x: 'Plausible' in x['test_results'])['bug_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33a005-5a5d-4b05-b05e-4016732e0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in repairllama_dataset:\n",
    "    if i['bug_id'] in pluasible_bug_id:\n",
    "        print(f\"------------------{i['bug_id']}------------------\")\n",
    "        print(i['buggy_code'])\n",
    "        indexes = [index for index, value in enumerate(i['test_results']) if value == 'Plausible']\n",
    "        print('plausible patches')\n",
    "        for j in indexes:\n",
    "            print('-------')            \n",
    "            print(i['patches'][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888d3f7-85ba-45f8-8f9a-4d8f070cd2a1",
   "metadata": {},
   "source": [
    "### our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b38f16ea-03a4-41bc-8c34-5e0685d57b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_from_disk('/Users/alex.wu/PycharmProjects/apr_datasets_processing/defects4j_validation/dataset_to_be_validated/defects4j_context_gen_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c5536ff-5a47-43d7-ae00-7af23b7f7711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def name_map(x):\n",
    "    x['bug_id']=x['projectName'].capitalize().replace('Jacksondatabind', 'JacksonDatabind').replace('Jacksoncore', 'JacksonCore').replace(\n",
    "            'Jacksonxml', 'JacksonXml').replace('Jxpath', 'JxPath').replace('_', '-')\n",
    "    x['gen']=[i.replace(x['input'], '').replace('<s>','').replace('</s>','').replace('<unk>','') for i in x['gen']]\n",
    "    return x\n",
    "\n",
    "dataset=dataset.map(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdec0daf-eb6d-4494-b532-c0224e374d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();',\n",
       " ' StringBuffer buff = new StringBuffer();']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8c15dd1-65dd-47d3-8f95-5f555a53f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_map(x):\n",
    "    x['bug_id']=x['projectName'].capitalize().replace('Jacksondatabind', 'JacksonDatabind').replace('Jacksoncore', 'JacksonCore').replace(\n",
    "            'Jacksonxml', 'JacksonXml').replace('Jxpath', 'JxPath').replace('_', '-')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7b710a9-8f12-4e06-89ad-cf24631086f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=dataset.map(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe98b5e-5419-49a8-9b7a-402b51b95cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04a48209-54ef-41a5-a240-05101df8d7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "our_pluasible_bug_id=dataset.filter(lambda x: 'plausible' in [i['correctness'] for i in x['test_res']])['bug_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b8433e2-0b0f-481b-8248-afe2555a6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id=list(set(our_pluasible_bug_id).difference(set(pluasible_bug_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f3fc0c2-1fbf-4e59-8e0a-d43e312e6b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_dataset=dataset.filter(lambda x:x['bug_id'] in unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31f2831c-7954-41cf-88ee-cb126035e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['methodInformation', 'involvedTypesInformation', 'filePath', 'classInformation', 'buggyInfo', 'projectName', 'input', 'output', 'gen', 'test_res', 'bug_id'],\n",
       "    num_rows: 11\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2701f24-f0a0-4fa4-894a-22069cfd9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unique_dataset:\n",
    "    print(f\"\\n\\n\")\n",
    "    print(f\"------------------{i['bug_id']}------------------\")\n",
    "    print('buggy_code:', i['buggyInfo']['buggyCode'])\n",
    "    print('fix_code:', i['buggyInfo']['originalCode'])\n",
    "    print('--our plausible patches:--')\n",
    "    for j in i['test_res']:\n",
    "        if j['correctness']=='plausible':\n",
    "            print('-------')            \n",
    "            print(j['patch'])\n",
    "    print('--repairllama patches:--')\n",
    "    print(repairllama_dataset.filter(lambda x:x['bug_id']==i['bug_id'])[0]['patches'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93389ee-9d6c-4323-a714-a463ee2c650a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fb855-eda1-41b1-a584-1f2c19fa34bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
